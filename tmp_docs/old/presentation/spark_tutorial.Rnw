\documentclass{beamer}
\usetheme{Warsaw}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\setbeamerfont{caption}{size=\scriptsize}

\title{Wprowadzenie do Apache Spark}
\author{Justyna Jankowiak}
\institute{Koło Naukowe Data Science, MiNI}
\date{19.04.2016}

\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Co to jest Apache Spark?}

\begin{columns}
  \begin{column}{0.5\textwidth}
    \begin{itemize}
    \item Jest to szybki silnik do~przetwarzania dużych danych.
    \item Główną zaletą Sparka jest możliwość wykonywania obliczeń w pamięci, co~przyspiesza działanie aplikacji.
  \end{itemize}
  
  \end{column}
  \begin{column}{0.5\textwidth}  %%<--- here
    \begin{center}
      \includegraphics[width=\textwidth]{spark_logo.png}
     \end{center}
  \end{column}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Historia rozwoju Sparka}
\begin{itemize}
\item \textbf{2009} - opracowanie oprogramowania na Uniwersytecie Kalifornijskim w Berkeley
\item \textbf{2010} - opublikowanie Sparka jako wolne oprogramowanie zgodnie z licencją BSD (Berkeley Software Distribution License)
\item \textbf{2013} - przekazanie Sparka do fundacji Apache Software
\item \textbf{od 2014} - Spark jest jednym z czołowych projektów Apache
\end{itemize}

\begin{columns}
  \begin{column}{0.5\textwidth}  %%<--- here
    \begin{center}
      \includegraphics[width=\textwidth]{uni_logo.jpg}
     \end{center}
  \end{column}
  \begin{column}{0.5\textwidth}  %%<--- here
    \begin{center}
      \includegraphics[width=\textwidth]{apache_logo.png}
     \end{center}
  \end{column}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Cechy Sparka}
\begin{itemize}
\item \textbf{Szybkość} - działa do 100 razy szybciej niż MapReduce z~wykorzystaniem pamięci operacyjnej i do 10 razy szybciej z~wykorzystaniem operacji dyskowych 
  \begin{figure}
  \includegraphics[width=0.3\textwidth]{logistic-regression.png}
  \vspace{-10pt}
  \caption{Źródło: http://spark.apache.org/}
  \end{figure}
\item \textbf{Łatwy w użyciu} - możliwość budowania aplikacji z~wykorzystaniem języków Java, Scala, Python lub R
\item \textbf{Zaawansowana analityka} - nie tylko operacje `map-reduce` ale również SQL, strumienie danych, machine learning oraz~algorytmy grafowe
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{RDD}
\textbf{Resilient Distributed Datasets} (leniwe kolekcje rozproszone :)) to~podstawowa struktura danych w Sparku. 
\begin{itemize}
\item Możliwość wykonywania równoległych operacji
\item Sposoby tworzenia RDD
\begin{itemize}
\item operacja \textit{parallelize} na "zwykłych" obiektach (np. liście) 
\item odwołanie do zewnętrznych źródeł danych (np. lokalny system plików lub HDFS)
\end{itemize}
\item Wykonujemy na nich dwie operacje
\begin{itemize}
\item transformacje (np. \textit{map}, \textit{filter})
\item akcje (np. \textit{collect}, \textit{reduce})
\end{itemize}
Wszystkie transforacje są leniwe, tzn. nie są wykonywane dopóki nie jest to konieczne. Wykonywane są dopiero, gdy następujące po nich akcje wymagają zwrócenia wyniku. 
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Rozszerzenia Spark Core}
\begin{figure}
\includegraphics[width=\textwidth]{spark_components.png}
  \vspace{-10pt}
  \caption{Źródło: http://spark.apache.org/}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Co dalej?}
Zachęcam do uczestnictwa w bezpłatnych kursach na platformie e-learningowej edX:

https://www.edx.org/xseries/data-science-engineering-spark

\end{frame}

\end{document}